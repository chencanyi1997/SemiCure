---
title: "semicure"
output: rmarkdown::html_vignette
vignette: |
  %\VignetteIndexEntry{semicure} 
  %\VignetteEngine{knitr::rmarkdown} 
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = TRUE
)
```


## Installation

You can install the released version of semicure from [Github](https://github.com/chencanyi1997/semicure) with:

``` r
devtools::install_github("chencanyi1997/semicure")
```

## Example

This is a basic example which shows you how to solve a common problem:

```{r example, eval=FALSE}
library(semicure)
## basic example code
demo(semicuredemo)
```

To see more through sample, you can check the vigenitte accompanied with the package. But you should install this package with the following code to build vigenitte. It will take a little time to build it.
```{r, eval=FALSE}
devtools::install_github("chencanyi1997/semicure", build_vignettes = TRUE, force = TRUE)
vignette("semicure")
```

## Introduction
The population survival function for a with covariates $\mathbf{Z}$ is given by
$$
S_{pop}(t|\mathbf{Z})=G_{\gamma}\{e^{\beta^T\mathbf{Z}}F(t)\},
$$
where
$$G_{\gamma}(x)=\left\{
\begin{aligned}
&(1+\gamma x)^{-1/\gamma}&,\quad \gamma>0 \\
&e^{-x}&, \quad \gamma=0.
\end{aligned}
\right.
$$
This class of models include the proportional hazards cure model and the proportional odds cure model as special cases. When $\gamma=0$, it reduces to the proportional hazards cure model; when $\gamma=1$, it has the proportional odds structure.

## Maximum likelihood estimation
Suppose that there are $n$ i.i.d. observations. For $i=1,\ldots,n$, we observe $\{Y_i,\Delta_i=I(T_i \leq Y_i),\mathbf{Z}_i\}$, where $T_i$ is the failure time for member $i$, $Y_i$ is the random censoring or inspection time,
$\mathbf{Z}_i$ is a vector of bounded covariates, and $I(\cdot)$ is the indicator function. The first component of $\mathbf{Z}_i$ is $1$. We assume that the inspection time $Y_i$ is conditionally independent of $T_i$ given $\mathbf{Z}_i$.

The observed-data likelihood function for the parameters $(\beta,F)$ can be expressed, for fixed $\gamma$, as
$$
L_n(\beta,F)=\prod_{i=1}^n\left[1-G_{\gamma}\{e^{\beta^T\mathbf{Z}_i}F(Y_i)\}\right]^{\Delta_i}\left[G_{\gamma}\{e^{\beta^T\mathbf{Z}_i}F(Y_i)\}\right]^{1-\Delta_i}.
$$
We wish to obtain the maximum likelihood estimators of $(\beta,F)$ by maximize the above likelihood function. The MLEs exist, however, they are not unique since the likelihood function depends on $F$ only through its value at the observed times $Y_i,i=1,\ldots,n$. Thus we focus on the maximization of $L_n(\beta,F)$ over all nondecreasing step functions with jumps at the $Y_i$'s for $F(t)$. We denote the MLEs of $\beta$ and $F$ by $\hat{\beta}_n$ and $\hat{F}_n$. Furthermore, we claim that $\hat{F}_n$ can only have jumps at those $Y_i$'s with $\Delta_i=1$. Let $s_1<\cdots<s_m$ denote the ordered distinct time points of $Y_i,i=1,\ldots,n$ with associated $\Delta_i=1$. For a subject with $\Delta_i=0$ and $s_k<Y_i<s_{k+1}$, consider two distribution functions $F_1$ and $F_2$. which have the same values at all time points except that $F_1(Y_i)=F_1(s_k)$ and $F_2(Y_i)>F_1(s_k)$. Since $G_{\gamma}(\cdot)$ is a decreasing function, it can be easily shown that $L_n(\beta,F_1)>L_n(\beta,F_2)$. Therefore, $\hat{F}_n$ can have positive jumps only at $s_k,k=1,\ldots,m$. Similarly, we can show that $\hat{F}_n(s_m)=1$ since $F$ is a proper distribution function. Therefore we maximize the likelihood function subject to the constraint that $0\leq F(s_1)\leq \cdots \leq F(s_m)=1$.

In this paper we use the following transformation
$$
F(s_k)=1-e^{-\sum_{j=1}^ke^{\alpha_j}}, k=1,\ldots,m-1
$$
and the constrained optimization problem reduces to the maximization of the likelihood function over $(\beta,\alpha_1,\ldots,\alpha_{m-1})$ without constraints. For small $m$, we use Newton-Raphson algorithm to solve the score equations for $\beta$ and $\{\alpha_k,k=1,\ldots,m-1\}$. When $m$ is large, we use the BFGS algorithm.

\begin{algorithm}[H]
\DontPrintSemicolon
\SetAlgoLined
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\Input{$\gamma,\{Y_i,Z_i,\Delta_i\}_{i=1}^n$.}
\Output{$\hat{\beta}_1,\hat{\beta}_2$ and $\hat{\alpha}_1,\ldots,\hat{\alpha}_{m-1}$.}
\BlankLine
Compute $m$ and find $s_1,\ldots,s_m$ defined in the previous section.

Initialize $\beta_0 = \beta_1 = \beta_2=0$.

Initialize $\alpha_1 = \log\{-\log(1-1/m)\},\alpha_k = \log[-\log\{1-\exp(\sum_{j=1}^{k-1}\alpha_j)/m\}],k=1,\ldots,m-1$, 

such that $\hat{F}$ has jump size of $1/m$ at $s_1,\ldots,s_m$.

\For{$i=1,\ldots,n$}{
  \eIf{$\Delta_i=1$}{
    Find index $k$ such that $Y_i=s_k$, and $l_i=\log\left[1-G_\gamma\{\mathrm{e}^{\beta^T Z_i} \hat{F}(s_k)\}\right].$
  }{
  Find index $k$ such that $s_k<Y_i<s_{k+1}$, and $l_i=\log\left[G_\gamma\{\mathrm{e}^{\beta^T Z_i} \hat{F}(s_k)\}\right]$
  }
}
Minimize the log-likelihood function $l_n(\beta,\alpha) = \sum_{i=1}^nl_i(\beta,\alpha)$ to obtain $(\hat{\beta},\hat{\alpha})$, where $\beta = (\beta_0,\beta_1,\beta_2),\alpha = (\alpha_1,\ldots,\alpha_{m-1})$.

\caption{Compute MLE using quasi-Newton method}
\end{algorithm}

## Simulation
We conducted simulation studies to examine the finite sample performance. We generate data from the model with $\mathbf{Z}=(1,Z_1,Z_2)^T$, where $Z_1$ is a uniform random variable in $[0,1]$, and $Z_2$ is a Bernoulli random variable with a success probability $0.5$. The true parameter values of $\beta=(\beta_0,\beta_1,\beta_2)$ are set to be $(-0.5,1,-0.5)$; and $F(t)=1-\{\exp(-t)-\exp(-t_0)\}I(t\leq t_0)/\{1-\exp(-t_0)\}$, where $t_0=4$. The inspection time was set to be the minimum of $4$ and an exponential variable with mean $2$. We considered five different models by varying the values of $\gamma$ from $0$ to $1$. The average cure rate ranged from $0.45$ to $0.56$ as $\alpha$ changed from $0$ to $1$, whereas the censoring proportion among those un-cured subjects was about $0.26$ for all five models. We considered sample sizes of $200$ and $400$ for each model. For each simulation set-up, we generated $1,000$ data sets. The initial values of the regression parameters were set to be $0$ and the initial jump sizes of $F$ were set to be $1/m$ at $s_1,\ldots,s_m$.

Table $1$ summarizes the results for each combination of $\gamma$ and $n$. The column labeled as "Mean" denotes the sampling mean of the parameter estimator from the true parameter value; "SE" is the sampling standard error of the parameter estimator; "SEE" is the mean of the standard error estimator, which is calculated based on the inverse of the observed information; and "CP(%)" is the coverage probability of the $95\%$ confidence interval based on the asymtotic normal approximation.

* Estimate:  $$\bar{\beta}_r^M = \frac{1}{M}\sum_{m=1}^M \hat{\beta}_r^{(m)},~~r=1,2.$$

* SE: $$SE(\hat{\beta}_r) = \left\{\frac{1}{M}\sum_{m=1}^M \left(\hat{\beta}_r^{(m)} - \bar{\beta}_r^M\right)^2\right\}^{1/2},~~r=1,2.$$

* SSE: In $m$th replication, $$SSE(\hat{\beta}^{(m)}) = J(\hat{\beta}^{(m)})^{-1/2} = \left\{ -\sum_{i=1}^n\frac{\partial ^2 l_i(\hat{\beta}^{(m)},\hat{\alpha}^{(m)})}{\partial \beta \partial \beta^T} \right\}^{-1/2},~~m=1,\ldots,M,$$
where $$\frac{\partial ^2 l_i(\hat{\beta}^{(m)},\hat{\alpha}^{(m)})}{\partial \beta \partial \beta^T} = \begin{cases} 
\frac{\left\{-G_\gamma''\left(a_i^{(m)}\right)a_i^{(m)} - G'_\gamma\left(a_i^{(m)}\right)\right\}(1-G_\gamma(a_i^{(m)})) - \left\{G'_\gamma(a_i^{(m)})\right\}^2 a_i^{(m)}}
{\left\{1-G_\gamma(a_i^{(m)})\right\}^2},  & \mbox{if }\Delta_i =1, \\
\frac{\left\{G_\gamma''\left(a_i^{(m)}\right)a_i^{(m)} + G'_\gamma\left(a_i^{(m)}\right)\right\}G_\gamma(a_i^{(m)}) - \left\{G'_\gamma(a_i^{(m)})\right\}^2 a_i^{(m)}}
{\left\{G_\gamma(a_i^{(m)})\right\}^2}, & \mbox{if }\Delta_i=0.
\end{cases}$$
In the equations above, $G'_\gamma(x),G''_\gamma(x)$ is the first and the second derivative with respect to $x$ respectively and $a_i^{(m)} = \mathrm{e}^{Z_i^T \hat{\beta}^{(m)}}\hat{F}(s_k)$, where $s_k$ is related to $Y_i$ according to the algorithm.
Finally, $$SSE(\hat{\beta}) = \frac{1}{M}\sum_{m=1}^M SSE(\hat{\beta}^{(m)})$$

* CP: By CLT, $\sqrt{n}(\hat{\beta}-\beta_0) \overset{\underset{\mathrm{d}}{}}{\longrightarrow} \mathrm{N}(0, I(\beta)^{-1})$. For each replication, construct a 95% confidence interval based on the asympototic distribution, then count the total number $K$ of times that the true value falls into the interval,  $CP = K/M \times 100\%.$

\begin{table}[htbp]
  \centering
    \begin{tabular}{rrlrlrrr}
    \multicolumn{8}{c}{Table1} \\
    \multicolumn{1}{l}{model} & \multicolumn{1}{l}{n} & parameter & \multicolumn{1}{l}{true value} & estimate & \multicolumn{1}{l}{SE} & \multicolumn{1}{l}{SEE} & \multicolumn{1}{l}{CP$(\%)$} \\
    \multicolumn{1}{l}{$\gamma=0$} & 200   & $\beta_1$ & 1     & 1.068938 & 0.4695524 & 0.4364619 & 0.939      \\
          &       & $\beta_2$ & -0.5  & -0.521181 & 0.2584653 & 0.2504274 & 0.937   \\
          & 400   & $\beta_1$ & 1     & 1.0505945 & 0.3250769 & 0.3089951 & 0.930   \\
          &       & $\beta_2$ & -0.5  & -0.5291623 & 0.1774480 & 0.1772027 & 0.954    \\
    \multicolumn{1}{l}{$\gamma=0.25$} & 200   & $\beta_1$ & 1     &  1.0264490 & 0.4101531 & 0.4171355 & 0.953   \\
          &       & $\beta_2$ & -0.5  & -0.5176226 & 0.2447230 & 0.2379094 & 0.943    \\
          & 400   & $\beta_1$ & 1     & 1.0093284 & 0.2932090 & 0.2886965 & 0.951    \\
          &       & $\beta_2$ & -0.5  & -0.5001677 & 0.1696949 & 0.1650536 & 0.948   \\
    0.5   & 200   & $\beta_1$ & 1     & 1.0358903 & 0.4981050 & 0.4751191 & 0.936    \\
          &       & $\beta_2$ & -0.5  & -0.5216513 & 0.2753877 & 0.2711459 & 0.952   \\
          & 400   & $\beta_1$ & 1     & 1.0075626 & 0.3348825 & 0.3261635 & 0.950   \\
          &       & $\beta_2$ & -0.5  & -0.5029296 & 0.1911795 & 0.1868073 & 0.944   \\
    0.75  & 200   & $\beta_1$ & 1     & 1.0402364 & 0.5617290 & 0.5317107 & 0.942      \\
          &       & $\beta_2$ & -0.5  & -0.5221529 & 0.3055167 & 0.3035736 & 0.952      \\
          & 400   & $\beta_1$ & 1     & 1.0539893 & 0.3814576 & 0.3710310 & 0.950      \\
          &       & $\beta_2$ & -0.5  & -0.5212664 & 0.2201302 & 0.2120356 & 0.939      \\
    \multicolumn{1}{l}{$\gamma=1$} & 200   & $\beta_1$ & 1     & 1.0507689 & 0.6450372 & 0.5942043 & 0.935    \\
          &       & $\beta_2$ & -0.5  & -0.5344726 & 0.3497060 & 0.3396732 & 0.942      \\
          & 400   & $\beta_1$ & 1     & 1.014476 & 0.4120969 & 0.4131133 & 0.957       \\
          &       & $\beta_2$ & -0.5  & -0.507400 & 0.2363958 & 0.2367635 & 0.950        \\
    \end{tabular}
\end{table}

The next line of simulation studies concerned about the performance of the commonly used proportional hazards cure model and the proportional odds cure model when data were generated from a different model. Specifically, we used the same setting for generating data in the simulation studies described earlier. The model with $\gamma=1/2$ corresponds to a model between the proportional hazards cure model and the proportional odds cure models. For each simulation setting, we generate $1,000$ replications with sample size of $n=400$. The results are summarized in Table $2$.


\begin{table}[htbp]
  \centering
    \begin{tabular}{rrlrlrrr}
    \multicolumn{8}{c}{Table2} \\
    \multicolumn{1}{l}{model} & \multicolumn{1}{l}{n} & parameter & \multicolumn{1}{l}{true value} & estimate & \multicolumn{1}{l}{SE} & \multicolumn{1}{l}{SEE} & \multicolumn{1}{l}{CP$(\%)$} \\
    1     & 400   & $\beta_1$ & 1     & 1.3937307 & 0.4186538 & 0.4096311 & 0.851   \\
          &       & $\beta_2$ & -0.5  & -0.6962886 & 0.2386292 & 0.2333729 & 0.874  \\
          &       &       &       &       &       &       &  \\
          &       &       &       &       &       &       &  \\
    2     & 400   & $\beta_1$ & 1     & 0.8187535 & 0.3240014 & 0.3309839 & 0.920   \\
          &       & $\beta_2$ & -0.5  & -0.4125800 & 0.1921661 & 0.1912553 & 0.915   \\
          &       &       &       &       &       &       &  \\
          &       &       &       &       &       &       &  \\
    3     & 400   & $\beta_1$ & 1     & 0.8513955 & 0.2909752 & 0.2779960 & 0.908   \\
          &       & $\beta_2$ & -0.5  & -0.4353248 & 0.1677679 & 0.1600703 & 0.929   \\
          &       &       &       &       &       &       &  \\
          &       &       &       &       &       &       &  \\
    4     & 400   & $\beta_1$ & 1     & 1.1673069 & 0.3901373 & 0.3818890 & 0.930   \\
          &       & $\beta_2$ & -0.5  & -0.5868782 & 0.2230797 & 0.2181379 & 0.931   \\
    \end{tabular}%
\end{table}

To reproduce the results listed above, you can follow the instruction below:
```{r setup, eval=FALSE}
devtools::install_github("chencanyi1997/semicure")
library(semicure)

# Reproduce table 1
set.seed(47)
for(gamma in seq(0,1,length.out = 5)){
  for(n in c(200,400)){
    reptable(gamma = gamma, n = n, rep = 1000, clusterN = 100 )
  }
}

# Reproduce table 2
for(gamma in seq(0,1,length.out = 3)){
  for(n in c(400)){
    reptable(gamma = gamma, n = n, rep = 1000, clusterN = 100 )
  }
}
```
